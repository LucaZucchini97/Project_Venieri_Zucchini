{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIKR module 3 project\n",
    "\n",
    "#Lorenzo Venieri\n",
    "#Luca Zucchini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "-Aggiungere funzione per trovare correlazione tra features\n",
    "-Considerare il fatto che il diabete causa durezza della pella, ma quest'ultima non è direttamente causa di diabete (=> != <=>)+\n",
    "-Piccola spiegazione del ragionamento dietro le correlazioni NON trovate\n",
    "-Fattore di rischio\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pgmpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#prva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "768 rows, 9 columns\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney\n",
    "Diseases. The objective of the dataset is to diagnostically predict whether a patient has diabetes,\n",
    "based on certain diagnostic measurements included in the dataset. Several constraints were placed\n",
    "on the selection of these instances from a larger database. In particular, all patients here are females\n",
    "at least 21 years old of Pima Indian heritage.2\n",
    "From the data set in the (.csv) File We can find several variables, some of them are independent\n",
    "(several medical predictor variables) and only one target dependent variable (Outcome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_raw = pd.read_csv(\"data/diabetes.csv\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  1,  8,  0,  5,  3, 10,  2,  4,  7,  9, 11, 13, 15, 17, 12, 14],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[\"Pregnancies\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che il dataset è sbilanciato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di outcome seza diabete 500\n",
      "Numero di outcome con diabete 268\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di outcome seza diabete\", (df_raw[\"Outcome\"] == 0).sum())\n",
    "print(\"Numero di outcome con diabete\", (df_raw[\"Outcome\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che ci sono tati valori nulli nel dataset. Sarebbero da togliere dato che sono dei NaN. Allo stesso tempo possiamo usare questa cosa per iniziare un downsample dei dati con Outcome '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_raw.columns:\n",
    "    print(\"    - nella colonna \", item,\" sono presenti questi zeri\")\n",
    "    print((df_raw[item] == 0).sum())\n",
    "    print(\"e questi sono tutti i valori disponibili:\")\n",
    "    temp = df_raw[item].unique()\n",
    "    temp.sort()\n",
    "    #print(df_raw[item].unique())\n",
    "    print(temp)\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_raw.columns:\n",
    "    counter = 0\n",
    "    for i in range(len(df_raw[item])):\n",
    "        if df_raw[item][i] == 0 and df_raw[\"Outcome\"][i] == 0:\n",
    "            counter += 1\n",
    "    print(\"nella colonna\", item,\"ci sono \",counter,\"righe da eliminare che possono semplicemente essere downsamplate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_raw.columns:\n",
    "    print(\"valori di \",item)\n",
    "    temp = df_raw[item].unique()\n",
    "    temp.sort()\n",
    "    #print(df_raw[item].unique())\n",
    "    print(temp)\n",
    "    print(\"----------------------\")\n",
    "    #\n",
    "    #chiedere a Sten dei bin sensati per questi valori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Togliamo le righe che hanno un valore nullo aka NaN e un outcome '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI','Age']\n",
    "for item in columns_to_clean:\n",
    "    drop_list = []\n",
    "    for i in range(len(df_clean[item])):\n",
    "        if df_clean[item][i] == 0 and df_clean[\"Outcome\"][i] == 0:\n",
    "            drop_list.append(i)\n",
    "    print(\"SIUUUM\")\n",
    "    df_clean.drop(labels= drop_list, axis= 0, inplace= True)\n",
    "    df_clean.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo tolto un po di roba, adiamo sia a vedere se e quanto è sbilanciato il dataset che a togliere le restati righe che hanno un NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di outcome seza diabete 262\n",
      "Numero di outcome con diabete 268\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di outcome seza diabete\", (df_clean[\"Outcome\"] == 0).sum())\n",
    "print(\"Numero di outcome con diabete\", (df_clean[\"Outcome\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Togliamo ora i restanti NaN senza però adare a toccare quelli dell'insulina ( presumiamo siano registrati nulli ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_clean.columns:\n",
    "    print(\"    - nella colonna \", item,\" sono presenti questi zeri\")\n",
    "    print((df_clean[item] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI','Age']\n",
    "\n",
    "for item in columns_to_clean:\n",
    "    drop_list = []\n",
    "    for i in range(len(df_clean[item])):\n",
    "        if df_clean[item][i] == 0 :\n",
    "            drop_list.append(i)\n",
    "    print(\"SIUUUM\")\n",
    "    df_clean.drop(labels= drop_list, axis= 0, inplace= True)\n",
    "    df_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bene, andiamo a vedere cosa rimane del dataset originario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di outcome seza diabete 262\n",
      "Numero di outcome con diabete 177\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di outcome seza diabete\", (df_clean[\"Outcome\"] == 0).sum())\n",
    "print(\"Numero di outcome con diabete\", (df_clean[\"Outcome\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come notiamo c'è ancora da fare un downsample per bilanciare il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_outcome = df_clean[df_clean[\"Outcome\"] == 1]\n",
    "df_negative_outcome = df_clean[df_clean[\"Outcome\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 9)\n"
     ]
    }
   ],
   "source": [
    "df_negative_outcome_downsampled = resample(df_negative_outcome,\n",
    "             replace=True,\n",
    "             n_samples=len(df_positive_outcome),\n",
    "             random_state=42)\n",
    "print(df_negative_outcome_downsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_negative_outcome_downsampled, df_positive_outcome])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di outcome seza diabete 177\n",
      "Numero di outcome con diabete 177\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di outcome seza diabete\", (df_balanced[\"Outcome\"] == 0).sum())\n",
    "print(\"Numero di outcome con diabete\", (df_balanced[\"Outcome\"] == 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_balanced.columns:\n",
    "    print(\"    - nella colonna \", item,\" sono presenti questi zeri\")\n",
    "    print((df_balanced[item] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bene, ora il dataset è bilanciato, non resta che binnarizzarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the min and max values of age in order to better discretize the age parameter\n",
    "print('Age range is: ', np.min(df_raw['Age']), ' - ', np.max(df_raw['Age']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In this chapter both the structure of the network, created from scratch by analyzing scientific papers related to the topic, and the parameter learning process are taken into account.\n",
    "\n",
    "In particular, a variety of methods related to the analysis of Bayesian Networks are explored.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the network\n",
    "\n",
    "A graphical preliminary overview of the network is shown using the visual library of pgmpy, the acronyms related to dataset attributes are the followings:\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install daft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "import matplotlib.pyplot as plt\n",
    "from daft import PGM\n",
    "\n",
    "pgm = PGM(shape=[6, 7])\n",
    "\n",
    "pgm.add_node(daft.Node('Gen', r\"Gen\", 2, 6))\n",
    "pgm.add_node(daft.Node('Age', r\"Age\", 1, 6))\n",
    "pgm.add_node(daft.Node('CPK', r\"CPK\", 3, 6))\n",
    "pgm.add_node(daft.Node('Smo', r\"Smo\", 4, 6))\n",
    "pgm.add_node(daft.Node('Sod', r\"Sod\", 5, 6))\n",
    "\n",
    "\n",
    "pgm.add_node(daft.Node('Ana', r\"Ana\", 2, 5))\n",
    "\n",
    "pgm.add_node(daft.Node('Dia', r\"Dia\", 1, 3))\n",
    "pgm.add_node(daft.Node('Blo', r\"Blo\", 3, 3))\n",
    "\n",
    "pgm.add_node(daft.Node('Fai', r\"Fai\", 3, 2))\n",
    "\n",
    "pgm.add_node(daft.Node('Eje', r\"Eje\", 2, 1))\n",
    "pgm.add_node(daft.Node('Pla', r\"Pla\", 4, 1))\n",
    "\n",
    "pgm.add_edge('Gen', 'CPK')\n",
    "pgm.add_edge('Gen', 'Dia')\n",
    "pgm.add_edge('Age', 'Dia')\n",
    "pgm.add_edge('Age', 'Ana')\n",
    "pgm.add_edge('Gen', 'Ana')\n",
    "pgm.add_edge('Dia', 'Blo')\n",
    "pgm.add_edge('CPK', 'Blo')\n",
    "pgm.add_edge('Ana', 'Blo')\n",
    "pgm.add_edge('Smo', 'Blo')\n",
    "pgm.add_edge('Sod', 'Blo')\n",
    "pgm.add_edge('Blo', 'Fai')\n",
    "pgm.add_edge('Dia', 'Fai')\n",
    "pgm.add_edge('Fai', 'Eje')\n",
    "pgm.add_edge('Fai', 'Pla')\n",
    "\n",
    "pgm.render()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of connections between nodes (e.g. direct cause, causal trail) refering to this specific Network are here shown:\n",
    "\n",
    "#Direct cause\n",
    "\n",
    "#Causal trail\n",
    "\n",
    "#Common effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network\n",
    "\n",
    "Connections between nodes have been implemented from scratch refering to a variety of scientific medical sources. Being the causal links in the medical field particularly challenging to model (i.e. often a huge variety of attributes are interlaced, causing directly or indirectly effects on each others) in this work only links that have been considered particularly relevant were defined.\n",
    "\n",
    "Some of the connections are here explained and referenced:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Analyzing the network\n",
    "\n",
    "Follows a series of experiments done on the network by applying a variety of methods provided by the pgmpy library in order to see in practice all the concepts addressed during the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all the nodes of the model\n",
    "model.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all the edges of the model\n",
    "model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local independecies of a single node\n",
    "model.local_independencies(\"high_blood_pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking d-separation between variables with and without evidence\n",
    "# Two sets of nodes X, Y are d-separated given Z if there is no active trail between any X ∈ X and Y ∈ Y given Z\n",
    "\n",
    "print(model.is_dconnected(\"high_blood_pressure\", \"creatinine_phosphokinase\"))\n",
    "print(model.is_dconnected(\"serum_sodium\", \"diabetes\",observed=[\"anaemia\"] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is_irrelevant made from scratch by the definition of irrelevance given during the course \n",
    "\n",
    "def is_irrelevant (node1,node2,evidence):\n",
    "  if ((node2 in (model.get_ancestral_graph(node1)and model.get_ancestral_graph(evidence))) and model.is_dconnected(node1, node2,observed=evidence )):\n",
    "    print(\"The node {0} is not irrelevant with resepect to {1}, given the evidence {2}.\".format(node1, node2, evidence))\n",
    "  else:\n",
    "    print(\"The node {0} is irrelevant with resepect to {1}, given the evidence {2}\".format(node1, node2, evidence))\n",
    "\n",
    "\n",
    "is_irrelevant(\"ejection_fraction\", \"diabetes\", \"heart_failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking active trails from high blood pressure given the evidence diabetes\n",
    "model.active_trail_nodes('high_blood_pressure', observed='diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the markov blanket of the node heart failure\n",
    "model.get_markov_blanket(\"heart_failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter learning\n",
    "\n",
    "Learning Bayesian networks from data, knowing the structure of the network, boils down to parameter estimation. In pgmpy a variety of estimators is available, going from IVestimator to SEMestimator, but the main choice for this problem fell on two of them: Maximum Likelihood and Bayesian Estimator.\n",
    "\n",
    "MLE, which depends solely on the outcomes of observed data, could be a reasonable simple starting point, however, it is notorious for becoming easily biased when the data is minimal. Moreover, in situations where observed data is sparse, Bayesian estimation’s incorporation of prior knowledge can help in attaining a more accurate model. \n",
    "\n",
    "On the other hand, unreliable priors can lead to a slippery slope of highly biased models that require large amounts of seen data to remedy; so priors need to be well defined and contain relevant insight to the problem in order to avoid that. \n",
    "\n",
    "Taken into consideration pros and cons of both approaches, given the minimal dataset used for this work the Bayesian Estimator is choosen.\n",
    "\n",
    "Pgmpy also offer a variety of possible priors, among them a possible choice is Bayesian Dirichlet equivalent uniform prior (BDeu), choosen with its default settings (i.e. equivalent_sample_size equal to 5).\n",
    "\n",
    "In the following cell the parameter estimation process takes place and the learned CPTs are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import BayesianEstimator\n",
    "\n",
    "model.cpds = []\n",
    "model.fit(data=df, estimator=BayesianEstimator, prior_type=\"BDeu\")\n",
    "\n",
    "for cpd in model.get_cpds():\n",
    "    print(f'CPT of {cpd.variable}:')\n",
    "    print(cpd, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the validity of the model \n",
    "# This method checks if the sum of the probabilities for each state is equal to 1 (tol=0.01) and if the CPDs associated with nodes are consistent with their parents.\n",
    "model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('ML4downsyndrome-D1DocbTt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e765655f724514810ca5f5619b481f72aea2afcac92a9986adb907bce56ced13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
